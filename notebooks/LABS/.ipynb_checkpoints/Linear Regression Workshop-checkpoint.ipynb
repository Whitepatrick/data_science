{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today we will be trying to demonstrate a few concepts\n",
    "\n",
    "- Linear regression is subject to the same kind of randomness t-tests are subject to. We will show why you need to be careful when interpreting linear regression coefficients\n",
    "- We will work on building and evaluating simple regression models\n",
    "- Building regressions with multiple variables\n",
    "- How to check to make sure assumptions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: You are given weights for 8 people. You will simulate data around how much money they have in their wallet that will have no relationship to their weight. You'll then ask linear regression to tell you if there is a relationship (knowing full well there isn't!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = [160, 185, 190, 200, 205, 220, 235, 280] #this will be your X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To prove that you need to be careful interpreting regression coefficiecnts, generate 7 N(60,10) random variables with numpy, and call that variable money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "money = np.random.normal(60, 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combine them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipped = zip(weight, money)\n",
    "df = pd.DataFrame(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['Weight', 'Money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = smf.ols(formula='Weight ~ Money', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Weight</td>      <th>  R-squared:         </th> <td>   0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 10 Dec 2015</td> <th>  Prob (F-statistic):</th>  <td> 0.331</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:32:35</td>     <th>  Log-Likelihood:    </th> <td> -38.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     8</td>      <th>  AIC:               </th> <td>   81.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   81.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  135.8531</td> <td>   70.621</td> <td>    1.924</td> <td> 0.103</td> <td>  -36.951   308.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Money</th>     <td>    1.2446</td> <td>    1.176</td> <td>    1.058</td> <td> 0.331</td> <td>   -1.633     4.122</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.471</td> <th>  Durbin-Watson:     </th> <td>   0.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.291</td> <th>  Jarque-Bera (JB):  </th> <td>   0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.060</td> <th>  Prob(JB):          </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.552</td> <th>  Cond. No.          </th> <td>    333.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Weight   R-squared:                       0.157\n",
       "Model:                            OLS   Adj. R-squared:                  0.017\n",
       "Method:                 Least Squares   F-statistic:                     1.120\n",
       "Date:                Thu, 10 Dec 2015   Prob (F-statistic):              0.331\n",
       "Time:                        18:32:35   Log-Likelihood:                -38.888\n",
       "No. Observations:                   8   AIC:                             81.78\n",
       "Df Residuals:                       6   BIC:                             81.93\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    135.8531     70.621      1.924      0.103       -36.951   308.657\n",
       "Money          1.2446      1.176      1.058      0.331        -1.633     4.122\n",
       "==============================================================================\n",
       "Omnibus:                        2.471   Durbin-Watson:                   0.844\n",
       "Prob(Omnibus):                  0.291   Jarque-Bera (JB):                0.107\n",
       "Skew:                           0.060   Prob(JB):                        0.948\n",
       "Kurtosis:                       3.552   Cond. No.                         333.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Weight', 'Money']\n",
    "X1 = df[feature_cols]\n",
    "y1 = df.Weight\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X1,y1)\n",
    "\n",
    "print lm.intercept_\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    135.853059\n",
       "Money          1.244646\n",
       "dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If you had to write the equation by hand what would it be? Calculate how much money the model expects you to have if you weigh 100 pounds. Interesting how the weight coefficient isn't 0 even though we know it should have no impact on money! Super important concept, if you don't understand this, ask a TA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260.317659"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "135.853059 + 1.244646*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is the p-value for the weight variable? Should you use it? If not, what is the new estimate for how much money someone who is 100 lbs has in their wallet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=12.679372977663412, pvalue=4.3901582011536774e-06)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.Weight, df.Money\n",
    "stats.ttest_rel(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Edwin hubble once measured the distance of nebulae outside of the Milkway Way, and was surprised that he found a relationship between a nebula's distance from the earth and the velocity with which it was moving away. This was the data the initially supported the idea of the big bang. Here you'll analyze the data and see if you come up with teh same conclusoin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read the data from \"../../data/nebula.csv\" and plot a scatter plot (plot.scatter(x,y)) - with velocity on the X axis, and distance on the Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../DAT-NYC-29/data/nebula.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>960</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>850</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>800</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1090</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Velocity  Distance\n",
       "19       960       1.7\n",
       "20       500       2.0\n",
       "21       850       2.0\n",
       "22       800       2.0\n",
       "23      1090       2.0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f01148081d0>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBklShcEgSar4f9seuNhTVqayAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0114984e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.Velocity, data.Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit the regression. According to the Big Bang theory, the distance should just be Time * Velocity (with no intercept). Does that relationship hold here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.634608\n",
       "Distance     0.000005\n",
       "dtype: float64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2 = smf.ols(formula='Velocity ~ Distance', data=data).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_time(velocity, distance):\n",
    "    time = distance / velocity\n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for row in data:\n",
    "    times.append(find_time(data.Velocity, data.Distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0     0.000176\n",
       " 1     0.000103\n",
       " 2    -0.001615\n",
       " 3    -0.003714\n",
       " 4    -0.001514\n",
       " 5    -0.001273\n",
       " 6     0.002250\n",
       " 7     0.001724\n",
       " 8     0.001852\n",
       " 9     0.003150\n",
       " 10    0.002667\n",
       " 11   -0.030000\n",
       " 12    0.001385\n",
       " 13    0.006000\n",
       " 14    0.001800\n",
       " 15    0.001087\n",
       " 16    0.002444\n",
       " 17    0.002200\n",
       " 18    0.002800\n",
       " 19    0.001771\n",
       " 20    0.004000\n",
       " 21    0.002353\n",
       " 22    0.002500\n",
       " 23    0.001835\n",
       " dtype: float64, 0     0.000176\n",
       " 1     0.000103\n",
       " 2    -0.001615\n",
       " 3    -0.003714\n",
       " 4    -0.001514\n",
       " 5    -0.001273\n",
       " 6     0.002250\n",
       " 7     0.001724\n",
       " 8     0.001852\n",
       " 9     0.003150\n",
       " 10    0.002667\n",
       " 11   -0.030000\n",
       " 12    0.001385\n",
       " 13    0.006000\n",
       " 14    0.001800\n",
       " 15    0.001087\n",
       " 16    0.002444\n",
       " 17    0.002200\n",
       " 18    0.002800\n",
       " 19    0.001771\n",
       " 20    0.004000\n",
       " 21    0.002353\n",
       " 22    0.002500\n",
       " 23    0.001835\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's see if we can manually calculate the R^2 value. The R2 is supposed to explain how well our linear regression fits the data. There are two main factors that go into an R2\n",
    "\n",
    "- Total Sum of Squares (TSS): This is a measure of how much the data varies overall. If this number is big, it means the data is all over the place, if it is small it means the data is similar. It is calculated by taking the sum of squares for the difference between the y-values, and the overall mean of the all the ys\n",
    "  - First calculate the mean of the ys\n",
    "  - Subtract it from each of the actual ys\n",
    "  - Square that subtraction\n",
    "  - Sum up the results\n",
    "- Residual Sum of Squares (RSS): This is effectively a measure for how much variation there is after you created your model. If you created a great model, the variation should be small. If the model didn't work, the varation will be big\n",
    "  - Predict what the values of y would be for the Xs that you have\n",
    "  - Subract the predicted (or fitted) ys from the actual ys\n",
    "  - Suare that difference\n",
    "  - Sum up the results\n",
    "- Now we can calculate the R^2 Value:\n",
    "  - (TSS-RSS)/TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Sum of Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculate the mean of the true Ys (Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Square the difference between the real Ys and the mean, and then sum it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yd = data.Distance.mean()\n",
    "diff = np.square(data.Distance - yd).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not quite sure if 9 is a 'big' number or not\n"
     ]
    }
   ],
   "source": [
    "float(diff)\n",
    "print \"I'm not quite sure if %d is a 'big' number or not\" % diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Sum of Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the values for what Y would be according to the model (Hint: you can can use lm.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Square the difference between the actual Ys and the fitted ys and sum it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now calculate the R^2. It should be very close to the one outputted by statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here you will try to understand the relationship between marketing spend and purchases made of your product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read in the spend data from \"../../data/spend.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spend = pd.read_csv(\"../DAT-NYC-29/data/spend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You notice that the model begins to taper out above. How can we better fit it than just spend vs purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### compare this with a model that doesnt use the Squared term. Which one should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
